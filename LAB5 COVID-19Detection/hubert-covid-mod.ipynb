{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from types import SimpleNamespace\nfrom functools import lru_cache\nimport os\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport pandas as pd\nimport numpy as np\nimport scipy.io.wavfile\nimport scipy.fftpack\nimport scipy.linalg\nimport torch\nimport torch.utils.data as data\nimport torch.nn as nn\nimport torch.optim as optim\nimport math\nimport random\ntorch.cuda.empty_cache()","metadata":{"papermill":{"duration":2.15566,"end_time":"2021-05-28T08:33:37.756848","exception":false,"start_time":"2021-05-28T08:33:35.601188","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-16T15:32:48.178015Z","iopub.execute_input":"2023-06-16T15:32:48.178730Z","iopub.status.idle":"2023-06-16T15:32:54.023661Z","shell.execute_reply.started":"2023-06-16T15:32:48.178683Z","shell.execute_reply":"2023-06-16T15:32:54.022495Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"MODEL = \"facebook/hubert-base-ls960\"","metadata":{"execution":{"iopub.status.busy":"2023-06-16T15:32:54.025578Z","iopub.execute_input":"2023-06-16T15:32:54.026189Z","iopub.status.idle":"2023-06-16T15:32:54.030819Z","shell.execute_reply.started":"2023-06-16T15:32:54.026147Z","shell.execute_reply":"2023-06-16T15:32:54.029714Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"seed = 1234\ndef seed_everything(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\nseed_everything(seed)","metadata":{"execution":{"iopub.status.busy":"2023-06-16T15:32:54.032465Z","iopub.execute_input":"2023-06-16T15:32:54.033202Z","iopub.status.idle":"2023-06-16T15:32:54.075566Z","shell.execute_reply.started":"2023-06-16T15:32:54.033166Z","shell.execute_reply":"2023-06-16T15:32:54.074575Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# 95% Confidence Interval for AUC. Hanley and McNeil (1982). https://gist.github.com/doraneko94/e24643136cfb8baf03ef8a314ab9615c\ndef roc_auc_score_ci(y_true, y_score, positive=1):\n    AUC = roc_auc_score(y_true, y_score)\n    N1 = sum(y_true == positive)\n    N2 = sum(y_true != positive)\n    Q1 = AUC / (2 - AUC)\n    Q2 = 2*AUC**2 / (1 + AUC)\n    SE_AUC = math.sqrt((AUC*(1 - AUC) + (N1 - 1)*(Q1 - AUC**2) + (N2 - 1)*(Q2 - AUC**2)) / (N1*N2))\n    lower = AUC - 1.96*SE_AUC\n    upper = AUC + 1.96*SE_AUC\n    if lower < 0:\n        lower = 0\n    if upper > 1:\n        upper = 1\n    return AUC, (lower, upper)","metadata":{"papermill":{"duration":0.021467,"end_time":"2021-05-28T08:33:37.871054","exception":false,"start_time":"2021-05-28T08:33:37.849587","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-16T15:32:54.078323Z","iopub.execute_input":"2023-06-16T15:32:54.079020Z","iopub.status.idle":"2023-06-16T15:32:54.086587Z","shell.execute_reply.started":"2023-06-16T15:32:54.078983Z","shell.execute_reply":"2023-06-16T15:32:54.085878Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Create a dataset with (key, wave_file, target_id) entries\ndef make_dataset(kaldi_path, class_to_id):\n    text_path = os.path.join(kaldi_path, 'text')     # labels\n    wav_path = os.path.join(kaldi_path, 'wav.scp')   # audio files\n\n    key_to_word = dict()\n    key_to_wav = dict()\n    \n    with open(wav_path, 'rt') as wav_scp:\n        for line in wav_scp:\n            key, wav = line.strip().split(' ', 1)\n            key_to_wav[key] = wav\n            key_to_word[key] = None # default\n\n    if os.path.isfile(text_path):\n        with open(text_path, 'rt') as text:\n            for line in text:\n                key, word = line.strip().split(' ', 1)\n                key_to_word[key] = word\n\n    wavs = []\n    for key, wav_command in key_to_wav.items():\n        word = key_to_word[key]\n        word_id = class_to_id[word] if word is not None else -1 # default for test\n        wav_item = [key, wav_command, word_id]\n        wavs.append(wav_item)\n\n    return wavs","metadata":{"papermill":{"duration":0.022733,"end_time":"2021-05-28T08:33:37.907067","exception":false,"start_time":"2021-05-28T08:33:37.884334","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-16T15:32:54.088073Z","iopub.execute_input":"2023-06-16T15:32:54.089219Z","iopub.status.idle":"2023-06-16T15:32:54.103478Z","shell.execute_reply.started":"2023-06-16T15:32:54.089181Z","shell.execute_reply":"2023-06-16T15:32:54.102361Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def wav_read(path):\n    sr, y = scipy.io.wavfile.read(path)\n    y = y/32768 # Normalize to -1..1\n    return y, sr","metadata":{"papermill":{"duration":0.019453,"end_time":"2021-05-28T08:33:37.939978","exception":false,"start_time":"2021-05-28T08:33:37.920525","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-16T15:32:54.105437Z","iopub.execute_input":"2023-06-16T15:32:54.106222Z","iopub.status.idle":"2023-06-16T15:32:54.117033Z","shell.execute_reply.started":"2023-06-16T15:32:54.106186Z","shell.execute_reply":"2023-06-16T15:32:54.116112Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from transformers import Wav2Vec2FeatureExtractor, HubertModel\n\n# Wav2Vec2 feature extractor\nprocessor = Wav2Vec2FeatureExtractor.from_pretrained(MODEL)","metadata":{"papermill":{"duration":1.216119,"end_time":"2021-05-28T08:33:39.169238","exception":false,"start_time":"2021-05-28T08:33:37.953119","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-16T15:32:54.118600Z","iopub.execute_input":"2023-06-16T15:32:54.119635Z","iopub.status.idle":"2023-06-16T15:33:04.387202Z","shell.execute_reply.started":"2023-06-16T15:32:54.119598Z","shell.execute_reply":"2023-06-16T15:33:04.386210Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)rocessor_config.json:   0%|          | 0.00/213 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d6b914a23354a8c9cd631d982de34a8"}},"metadata":{}}]},{"cell_type":"code","source":"# Preprocessing of the input sample (padding)\ndef param_loader(path, max_seconds):\n    wav, sfr = wav_read(path)\n    wav = wav.astype(np.float32)\n    wav -= wav.mean()\n    wav.resize(max_seconds*sfr)\n    y = processor(wav, sampling_rate=sfr, return_tensors=\"np\").input_values\n    y = y.squeeze(0).astype(np.float32)\n    return y","metadata":{"papermill":{"duration":0.023011,"end_time":"2021-05-28T08:33:39.20815","exception":false,"start_time":"2021-05-28T08:33:39.185139","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-16T15:33:04.388959Z","iopub.execute_input":"2023-06-16T15:33:04.389689Z","iopub.status.idle":"2023-06-16T15:33:04.397279Z","shell.execute_reply.started":"2023-06-16T15:33:04.389650Z","shell.execute_reply":"2023-06-16T15:33:04.396298Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Target values and id mapping\ndef get_classes():\n    classes = ['neg', 'pos']\n    weight = None\n    class_to_id = {label: i for i, label in enumerate(classes)}\n    return classes, weight, class_to_id","metadata":{"papermill":{"duration":0.021012,"end_time":"2021-05-28T08:33:39.243971","exception":false,"start_time":"2021-05-28T08:33:39.222959","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-16T15:33:04.399008Z","iopub.execute_input":"2023-06-16T15:33:04.399801Z","iopub.status.idle":"2023-06-16T15:33:04.414035Z","shell.execute_reply.started":"2023-06-16T15:33:04.399762Z","shell.execute_reply":"2023-06-16T15:33:04.412930Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# PyTorch Dataset\nclass Loader(data.Dataset):\n\n    def __init__(self, root, max_seconds=10):\n\n        classes, weight, class_to_id = get_classes()\n        self.root = root\n        self.wavs = make_dataset(root, class_to_id)\n        self.classes = classes\n        self.weight = weight\n        self.class_to_id = class_to_id\n        self.loader = param_loader\n        self.max_seconds = max_seconds\n\n    def __getitem__(self, index):\n        \"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (key, params, target) where target is class_index of the target class.\n        \"\"\"\n        key, path, target = self.wavs[index]\n        path = '../input/covid3/wavs16k/' + path\n        params = self.loader(path, self.max_seconds)\n        return key, params, target\n\n    def __len__(self):\n        return len(self.wavs)","metadata":{"papermill":{"duration":0.023628,"end_time":"2021-05-28T08:33:39.282485","exception":false,"start_time":"2021-05-28T08:33:39.258857","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-16T15:33:04.419123Z","iopub.execute_input":"2023-06-16T15:33:04.420105Z","iopub.status.idle":"2023-06-16T15:33:04.429395Z","shell.execute_reply.started":"2023-06-16T15:33:04.420068Z","shell.execute_reply":"2023-06-16T15:33:04.428637Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Baseline model using a pre-trained HubertModel","metadata":{"papermill":{"duration":0.014684,"end_time":"2021-05-28T08:33:39.311956","exception":false,"start_time":"2021-05-28T08:33:39.297272","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class HubertForAudioClassification(nn.Module):\n    def __init__(self, adapter_hidden_size=64):\n        super().__init__()\n\n        self.hubert = HubertModel.from_pretrained(MODEL, output_attentions=False, output_hidden_states=True)\n        hidden_size = self.hubert.config.hidden_size\n\n        self.layer_weights = nn.Parameter(torch.ones(2) / 2)\n\n        self.adaptor = nn.Sequential(\n            nn.Linear(hidden_size, adapter_hidden_size),\n            nn.ReLU(True),\n            nn.Dropout(0.1),\n            nn.Linear(adapter_hidden_size, hidden_size),\n        )\n\n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_size, adapter_hidden_size),\n            nn.ReLU(True),\n            nn.Dropout(0.1),\n            nn.Linear(adapter_hidden_size, 1),\n        )\n\n    def freeze_feature_encoder(self):\n        \"\"\"\n        Calling this function will disable the gradient computation for the feature encoder so that its parameter will\n        not be updated during training.\n        \"\"\"\n        self.hubert.feature_extractor._freeze_parameters()\n\n    def forward(self, x):\n        # x shape: (B, E)\n        outputs = self.hubert(x)\n        hidden_states = outputs.hidden_states[-2:]  # Last two hidden states\n        hidden_states = torch.stack(hidden_states, dim=1)\n        norm_weights = nn.functional.softmax(self.layer_weights, dim=-1)\n        weighted_states = (hidden_states * norm_weights.view(1, -1, 1, 1)).sum(dim=1)\n\n        x = self.adaptor(weighted_states)\n\n        # Pooling\n        x, _ = x.max(dim=1)\n\n        # Multilayer perceptron\n        out = self.classifier(x)\n        # out shape: (B, 1)\n\n        # Remove last dimension\n        return out.squeeze(-1)\n        # return shape: (B)\n","metadata":{"id":"79opq8kbeIQ9","papermill":{"duration":0.023956,"end_time":"2021-05-28T08:33:39.351023","exception":false,"start_time":"2021-05-28T08:33:39.327067","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-16T16:45:44.613394Z","iopub.execute_input":"2023-06-16T16:45:44.613776Z","iopub.status.idle":"2023-06-16T16:45:44.629806Z","shell.execute_reply.started":"2023-06-16T16:45:44.613745Z","shell.execute_reply":"2023-06-16T16:45:44.628494Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"layer_weights = nn.Parameter(torch.ones(2) / 2)\n#layer_weights\nnn.functional.softmax(layer_weights, dim=-1)","metadata":{"execution":{"iopub.status.busy":"2023-06-16T16:34:09.221542Z","iopub.execute_input":"2023-06-16T16:34:09.222110Z","iopub.status.idle":"2023-06-16T16:34:09.236991Z","shell.execute_reply.started":"2023-06-16T16:34:09.222057Z","shell.execute_reply":"2023-06-16T16:34:09.235796Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"tensor([0.5000, 0.5000], grad_fn=<SoftmaxBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"def train(loader, model, criterion, optimizer, epoch, cuda, log_interval, max_norm=1, verbose=True):\n    model.train()\n    global_epoch_loss = 0\n    samples = 0\n    for batch_idx, (_, data, target) in enumerate(loader):\n        if cuda:\n            data, target = data.cuda(), target.cuda()\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target.float())\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n        optimizer.step()\n        global_epoch_loss += loss.data.item() * len(target)\n        samples += len(target)\n        if verbose and (batch_idx % log_interval == 0):\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, samples, len(loader.dataset), 100*samples/len(loader.dataset), global_epoch_loss/samples))\n    return global_epoch_loss / samples","metadata":{"papermill":{"duration":0.024428,"end_time":"2021-05-28T08:33:39.390835","exception":false,"start_time":"2021-05-28T08:33:39.366407","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-16T15:33:04.450403Z","iopub.execute_input":"2023-06-16T15:33:04.450864Z","iopub.status.idle":"2023-06-16T15:33:04.467346Z","shell.execute_reply.started":"2023-06-16T15:33:04.450830Z","shell.execute_reply":"2023-06-16T15:33:04.466460Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def test(loader, model, criterion, cuda, verbose=True, data_set='Test', save=None):\n    model.eval()\n    test_loss = 0\n    tpred = []\n    ttarget = []\n\n    if save is not None:\n        csv = open(save, 'wt')\n        print('index,prob', file=csv)\n\n    with torch.no_grad():\n        for keys, data, target in loader:\n            if cuda:\n                data, target = data.cuda(), target.cuda()\n            output = model(data)\n            pred = output.sigmoid()\n            tpred.append(pred.cpu().numpy())\n\n            if target[0] != -1:\n                loss = criterion(output, target.float()).data.item()\n                test_loss += loss * len(target) # sum up batch loss \n                ttarget.append(target.cpu().numpy())\n\n            if save is not None:\n                for i, key in enumerate(keys):\n                    print(f'{key},{pred[i]}', file=csv)\n    \n    if len(ttarget) > 0:\n        test_loss /= len(loader.dataset)\n        auc, auc_ci = roc_auc_score_ci(np.concatenate(ttarget), np.concatenate(tpred))\n        if verbose:\n            print('\\n{} set: Average loss: {:.4f}, AUC: {:.1f}% ({:.1f}% - {:.1f}%)\\n'.format(\n                data_set, test_loss, 100 * auc, auc_ci[0]*100, auc_ci[1]*100))\n\n        return test_loss, auc","metadata":{"papermill":{"duration":0.026812,"end_time":"2021-05-28T08:33:39.432755","exception":false,"start_time":"2021-05-28T08:33:39.405943","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-16T15:33:04.469320Z","iopub.execute_input":"2023-06-16T15:33:04.469701Z","iopub.status.idle":"2023-06-16T15:33:04.485397Z","shell.execute_reply.started":"2023-06-16T15:33:04.469666Z","shell.execute_reply":"2023-06-16T15:33:04.484190Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"args = SimpleNamespace(\n    # general options\n    train_path = '../input/covid3/train',        # train data folder\n    valid_path = '../input/covid3/valid',        # valid data folder\n    test_path = '../input/covid3/test',          # test data folder\n    batch_size = 15,                             # training and valid batch size\n    test_batch_size = 15,                        # batch size for testing\n    epochs = 50,                                 # maximum number of epochs to train\n    lr = 0.001,                                 # learning rate\n    momentum = 0.9,                              # SGD momentum, for SGD only\n    optimizer = 'adam',                          # optimization method: sgd | adam\n    seed = seed,                                 # random seed\n    log_interval = 5,                            # how many batches to wait before logging training status\n    patience = 5,                                # how many epochs of no loss improvement should we wait before stop training\n    checkpoint = '.',                            # checkpoints directory\n    train = True,                                # train before testing\n    cuda = True,                                 # use gpu\n    num_workers = 2,                             # how many subprocesses to use for data loading\n    adapter_hidden_size = 32\n)","metadata":{"papermill":{"duration":0.02237,"end_time":"2021-05-28T08:33:39.469897","exception":false,"start_time":"2021-05-28T08:33:39.447527","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-16T15:33:04.486924Z","iopub.execute_input":"2023-06-16T15:33:04.487929Z","iopub.status.idle":"2023-06-16T15:33:04.503233Z","shell.execute_reply.started":"2023-06-16T15:33:04.487901Z","shell.execute_reply":"2023-06-16T15:33:04.502206Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"args.cuda = args.cuda and torch.cuda.is_available()\nif args.cuda:\n    print('Using CUDA with {0} GPUs'.format(torch.cuda.device_count()))\n\n# build model\nmodel = HubertForAudioClassification(adapter_hidden_size=args.adapter_hidden_size)\nif args.cuda:\n    model.cuda()\n\n# Define criterion\ncriterion = nn.BCEWithLogitsLoss(reduction='mean') # This loss combines a Sigmoid layer and the BCELoss in one single class.","metadata":{"papermill":{"duration":19.642201,"end_time":"2021-05-28T08:33:59.126786","exception":false,"start_time":"2021-05-28T08:33:39.484585","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-16T15:33:04.506686Z","iopub.execute_input":"2023-06-16T15:33:04.506983Z","iopub.status.idle":"2023-06-16T15:33:14.459043Z","shell.execute_reply.started":"2023-06-16T15:33:04.506959Z","shell.execute_reply":"2023-06-16T15:33:14.458067Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Using CUDA with 1 GPUs\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54f87306c8304f498cb109f4977e7cf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/378M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78724e3236c340c29182d78d0ce1f4da"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Train model","metadata":{"papermill":{"duration":0.016009,"end_time":"2021-05-28T08:33:59.159341","exception":false,"start_time":"2021-05-28T08:33:59.143332","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# partial freeze of wac2vec parameters. Only feature_projection parameters are fine tuned\nmodel.freeze_feature_encoder()\nfor param in model.hubert.encoder.parameters():\n    param.requires_grad = False\nmodel.hubert","metadata":{"papermill":{"duration":0.0304,"end_time":"2021-05-28T08:33:59.205822","exception":false,"start_time":"2021-05-28T08:33:59.175422","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-16T15:33:14.460485Z","iopub.execute_input":"2023-06-16T15:33:14.460881Z","iopub.status.idle":"2023-06-16T15:33:14.472736Z","shell.execute_reply.started":"2023-06-16T15:33:14.460851Z","shell.execute_reply":"2023-06-16T15:33:14.471788Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"HubertModel(\n  (feature_extractor): HubertFeatureEncoder(\n    (conv_layers): ModuleList(\n      (0): HubertGroupNormConvLayer(\n        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n        (activation): GELUActivation()\n        (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n      )\n      (1-4): 4 x HubertNoLayerNormConvLayer(\n        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n        (activation): GELUActivation()\n      )\n      (5-6): 2 x HubertNoLayerNormConvLayer(\n        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n        (activation): GELUActivation()\n      )\n    )\n  )\n  (feature_projection): HubertFeatureProjection(\n    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (projection): Linear(in_features=512, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): HubertEncoder(\n    (pos_conv_embed): HubertPositionalConvEmbedding(\n      (conv): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n      (padding): HubertSamePadLayer()\n      (activation): GELUActivation()\n    )\n    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (layers): ModuleList(\n      (0-11): 12 x HubertEncoderLayer(\n        (attention): HubertAttention(\n          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.1, inplace=False)\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (feed_forward): HubertFeedForward(\n          (intermediate_dropout): Dropout(p=0.1, inplace=False)\n          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n          (output_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import HubertModel\n\n# Replace 'MODEL' with the specific model name or path\nmodel = HubertModel.from_pretrained(MODEL)\nmodel.cuda()\n\nnewmodel = torch.nn.Sequential(*(list(model.children())))\nsub = torch.nn.Sequential(*(list(newmodel[2].children())))\nsub[3][0]","metadata":{"execution":{"iopub.status.busy":"2023-06-16T15:33:14.474129Z","iopub.execute_input":"2023-06-16T15:33:14.474710Z","iopub.status.idle":"2023-06-16T15:33:16.954830Z","shell.execute_reply.started":"2023-06-16T15:33:14.474676Z","shell.execute_reply":"2023-06-16T15:33:16.953721Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"HubertEncoderLayer(\n  (attention): HubertAttention(\n    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  (feed_forward): HubertFeedForward(\n    (intermediate_dropout): Dropout(p=0.1, inplace=False)\n    (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n    (intermediate_act_fn): GELUActivation()\n    (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n    (output_dropout): Dropout(p=0.1, inplace=False)\n  )\n  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# loading data\nif args.train:\n    train_dataset = Loader(args.train_path)\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers)\n\n    valid_dataset = Loader(args.valid_path)\n    valid_loader = torch.utils.data.DataLoader(\n        valid_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n\n    # define optimizer\n    if args.optimizer.lower() == 'adam':\n        optimizer = optim.Adam(model.parameters(), lr=args.lr)\n    else:\n        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n\n    best_valid_auc = 0\n    iteration = 0\n    epoch = 1\n    best_epoch = epoch\n    \n    # training with early stopping\n    t0 = time.time()\n    while (epoch < args.epochs + 1) and (iteration < args.patience):\n        train(train_loader, model, criterion, optimizer, epoch, args.cuda, args.log_interval)\n        valid_loss, valid_auc = test(valid_loader, model, criterion, args.cuda, data_set='Validation')\n        if not os.path.isdir(args.checkpoint):\n            os.mkdir(args.checkpoint)\n        torch.save(model.state_dict(), './{}/model{:03d}.pt'.format(args.checkpoint, epoch))\n        if valid_auc <= best_valid_auc:\n            iteration += 1\n            print('AUC was not improved, iteration {0}'.format(str(iteration)))\n        else:\n            print('Saving state')\n            iteration = 0\n            best_valid_auc = valid_auc\n            best_epoch = epoch\n            state = {\n                'valid_auc': valid_auc,\n                'valid_loss': valid_loss,\n                'epoch': epoch,\n            }\n            if not os.path.isdir(args.checkpoint):\n                os.mkdir(args.checkpoint)\n            torch.save(state, './{}/ckpt.pt'.format(args.checkpoint))\n        epoch += 1\n        print(f'Elapsed seconds: ({time.time() - t0:.0f}s)')\n    print(f'Best AUC: {best_valid_auc*100:.1f}% on epoch {best_epoch}')","metadata":{"papermill":{"duration":2624.898624,"end_time":"2021-05-28T09:17:44.12129","exception":false,"start_time":"2021-05-28T08:33:59.222666","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-05T17:56:15.517972Z","iopub.execute_input":"2022-05-05T17:56:15.518347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test Model","metadata":{"papermill":{"duration":0.176713,"end_time":"2021-05-28T09:17:44.474513","exception":false,"start_time":"2021-05-28T09:17:44.2978","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_dataset = Loader(args.test_path)\ntest_loader = torch.utils.data.DataLoader(\n    test_dataset, batch_size=args.test_batch_size, shuffle=False, num_workers=args.num_workers)\n\n# get best epoch and model\nstate = torch.load('./{}/ckpt.pt'.format(args.checkpoint))\nepoch = state['epoch']\nprint(\"Testing model (epoch {})\".format(epoch))\nmodel.load_state_dict(torch.load('./{}/model{:03d}.pt'.format(args.checkpoint, epoch)))\nif args.cuda:\n    model.cuda()\n\nresults = 'submission.csv'\nprint(\"Saving results in {}\".format(results))\ntest(test_loader, model, criterion, args.cuda, save=results)","metadata":{"papermill":{"duration":16.550646,"end_time":"2021-05-28T09:18:01.199088","exception":false,"start_time":"2021-05-28T09:17:44.648442","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}